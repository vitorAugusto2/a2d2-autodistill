{"cells":[{"cell_type":"markdown","metadata":{"id":"R1m3pvTeVLVl"},"source":["# üß™ PIP INSTALL\n","Instalar pacotes: Autodistill, GroundedSAM, YOLOv8, Supervision e Roboflow\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eyNoxNFGMcFa"},"outputs":[],"source":["!pip install -q \\\n","autodistill \\\n","autodistill-grounded-sam \\\n","autodistill-yolov8 \\\n","supervision==0.9.0 \\\n","roboflow"]},{"cell_type":"markdown","metadata":{"id":"tNz69EehVNpw"},"source":["# üóÇÔ∏è IMPORT\n","**NOTE**: Bibliotecas principais como autodistill (CaptionOntology, GroundedSAM e YOLOv8) para lidar com rotulagem automatica e detec√ß√£o de objetos\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_UgPrQB-L8kz"},"outputs":[],"source":["import os\n","import cv2\n","import supervision as sv\n","from autodistill.detection import CaptionOntology\n","from autodistill_grounded_sam import GroundedSAM\n","from autodistill_yolov8 import YOLOv8\n","from IPython.display import Image"]},{"cell_type":"markdown","metadata":{"id":"5aQS__bUMniD"},"source":["# üñºÔ∏è PREPARANDO DADOS"]},{"cell_type":"markdown","metadata":{"id":"IGe6kzzwiYcr"},"source":["### Carregando imagens"]},{"cell_type":"markdown","metadata":{"id":"06mAo0X6hUnn"},"source":["Definindo o diretorio atual e vizualizando"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u910UZMmNb2N"},"outputs":[],"source":["HOME = os.getcwd()\n","print(HOME)"]},{"cell_type":"markdown","metadata":{"id":"I1gytXhKhaUY"},"source":["Cria um diret√≥rio chamado `images` no dict `HOME`, para carregar as imagens atraves do GitHub\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O46ZL2tITLtt"},"outputs":[],"source":["!mkdir {HOME}/images\n","!git clone https://github.com/vitorAugusto2/tcc-a2d2.git\n","!mv {HOME}/tcc-a2d2/images/* {HOME}/images/\n","!rm -rf {HOME}/tcc-a2d2"]},{"cell_type":"markdown","metadata":{"id":"HSJmW7GeiOVz"},"source":["### Exibir amostra de imagem nao rotulada"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l_XhXOkfVx36"},"outputs":[],"source":["IMAGE_DIR_PATH = f\"{HOME}/images\"\n","\n","image_paths = sv.list_files_with_extensions(\n","    directory=IMAGE_DIR_PATH,\n","    extensions=[\"png\"])\n","\n","print(f\"Quantidades de imagens: {len(image_paths)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"23O021NzVycF"},"outputs":[],"source":["SAMPLE_SIZE = 16\n","SAMPLE_GRID_SIZE = (4, 4)\n","SAMPLE_PLOT_SIZE = (16, 16)\n","\n","titles = [\n","    image_path.stem\n","    for image_path\n","    in image_paths[:SAMPLE_SIZE]]\n","images = [\n","    cv2.imread(str(image_path))\n","    for image_path\n","    in image_paths[:SAMPLE_SIZE]]\n","\n","sv.plot_images_grid(images=images, titles=titles, grid_size=SAMPLE_GRID_SIZE, size=SAMPLE_PLOT_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"UFafQRbzWw5f"},"source":["# üî™ AUTODISTILL: ROTULO AUTOMATICO"]},{"cell_type":"markdown","metadata":{"id":"70PFxofdjUkJ"},"source":["### Definir ontologia\n","\n","**Ontologia** - uma Ontologia define como seu Modelo Base √© solicitado, o que seu Conjunto de Dados descrever√° e o que seu Modelo Alvo ir√° prever. Uma ontologia simples √© a CaptionOntology que solicita um modelo base com legendas de texto e as mapeia para nomes de classes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ij_VIC7sW5X1"},"outputs":[],"source":["\"\"\"\n","  Ontology: como o modelo base √© solicitado\n","  Descreve o que voce realmente ve no conjunto de dados e no que deseja treinar\n","  seu modelo destino\n","\n","  Lancar os prompts e classes para gerar as mascaras de segmentacao\n","    -> (prompt : class)\n","\"\"\"\n","\"\"\"\n","  Classificar as classes de interesse, exemplo:\n","  ```python\n","    ontology=CaptionOntology({\n","      \"car\": \"car\",\n","      \"pedestrian\": \"pedestrian\",\n","      \"tree\": \"tree\"\n","    })\n","  ```\n","\"\"\"\n","\n","ontology=CaptionOntology({\n","  # digite (prompt : class)\n","})"]},{"cell_type":"markdown","metadata":{"id":"-vGpDutTkUTY"},"source":["### Iniciar modelo base e r√≥tulo autom√°tico\n","\n","**Ontologia** - define como seu Modelo Base √© solicitado, o que seu Conjunto de Dados descrever√° e o que seu Modelo Alvo ir√° prever. Uma ontologia simples √© aquela CaptionOntologyque solicita um modelo base com legendas de texto e os mapeia para nomes de classes.\n","- Uma ontologia em Computa√ß√£o √© um modelo de dados que representa um conjunto de conceitos dentro de um dom√≠nio e os relacionamentos entre estes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88KVGehhW9xZ"},"outputs":[],"source":["DATASET_DIR_PATH = f\"{HOME}/dataset\" # diretorio de treinamento do dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lVRSJ4HdXDGr"},"outputs":[],"source":["# Modelo base √© iniciado por ontology\n","base_model = GroundedSAM(ontology=ontology) # modelo base: GroundedSAM\n","dataset = base_model.label(\n","    input_folder=IMAGE_DIR_PATH,      # entrada de dados\n","    extension=\".png\",                 # extensao da imagem .png\n","    output_folder=DATASET_DIR_PATH)   # armazena a saida dos dados rotulados"]},{"cell_type":"markdown","metadata":{"id":"cao6J8oqk9SY"},"source":["### Exibir amostra do conjunto de dados\n","\n","**Conjunto de dados/dataset** - dados rotulados automaticamente que pode ser usado para treinar um modelo de destino, como por exemplo YOLOv8. √â a sa√≠da gerada por um Modelo Base."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7ylSE1yuXMOG"},"outputs":[],"source":["ANNOTATIONS_DIRECTORY_PATH = f\"{HOME}/dataset/train/labels\" # dados de rotulagem das imagens treinadas\n","IMAGES_DIRECTORY_PATH = f\"{HOME}/dataset/train/images\"      # imagens de treino rotuladas\n","DATA_YAML_PATH = f\"{HOME}/dataset/data.yaml\"                # arquivo formato YOLO (.yaml -> id, x, y, largura, altura)"]},{"cell_type":"markdown","metadata":{"id":"Hg3s2LY3mZjO"},"source":["**NOTA**: a quantidade de imagens total √© dividida em `train` e `valid`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AlB29NoQXSp1"},"outputs":[],"source":["dataset = sv.DetectionDataset.from_yolo(\n","    images_directory_path=IMAGES_DIRECTORY_PATH,\n","    annotations_directory_path=ANNOTATIONS_DIRECTORY_PATH,\n","    data_yaml_path=DATA_YAML_PATH)\n","\n","len(dataset) # quantidade de imagens de treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lq1J-652XTqi"},"outputs":[],"source":["\"\"\"\n","  Exemplos de imagens; Loop for em execucao com todos os parametros que criam\n","  essa imagens de anotacao com mascara de segmentacao e anotador de caixa de\n","  supervisao; e tambem dados demograficos para tracar nossa grade de imagens\n","\"\"\"\n","\n","SAMPLE_SIZE = 16\n","SAMPLE_GRID_SIZE = (4, 4)\n","SAMPLE_PLOT_SIZE = (16, 16)\n","\n","image_names = list(dataset.images.keys())[:SAMPLE_SIZE]\n","\n","mask_annotator = sv.MaskAnnotator()\n","box_annotator = sv.BoxAnnotator()\n","\n","images = []\n","for image_name in image_names:\n","    image = dataset.images[image_name]\n","    annotations = dataset.annotations[image_name]\n","    labels = [\n","        dataset.classes[class_id]\n","        for class_id\n","        in annotations.class_id]\n","    annotates_image = mask_annotator.annotate(\n","        scene=image.copy(),\n","        detections=annotations)\n","    annotates_image = box_annotator.annotate(\n","        scene=annotates_image,\n","        detections=annotations,\n","        labels=labels)\n","    images.append(annotates_image)\n","\n","sv.plot_images_grid(\n","    images=images,\n","    titles=image_names,\n","    grid_size=SAMPLE_GRID_SIZE,\n","    size=SAMPLE_PLOT_SIZE)"]},{"cell_type":"markdown","metadata":{"id":"qxHrdgXNXXui"},"source":["# üöòYOLOV8\n"]},{"cell_type":"markdown","metadata":{"id":"XGpMV-9QoLWY"},"source":["### Treinamento do modelo\n","**Modelo de destino** ‚Äì √© um modelo supervisionado que consome um conjunto de dados e gera um modelo destilado que est√° pronto para implanta√ß√£o. Os modelos de destino geralmente s√£o pequenos, r√°pidos e ajustados para executar muito bem uma tarefa espec√≠fica (mas n√£o generalizam muito al√©m das informa√ß√µes descritas em seu conjunto de dados)."]},{"cell_type":"markdown","metadata":{"id":"WW_E3M5wnK2o"},"source":["**NOTA**: A interface de linha de comando YOLO (CLI) permite comandos simples de linha √∫nica sem a necessidade de um ambiente Python. CLI n√£o requer personaliza√ß√£o ou c√≥digo Python . Podes simplesmente executar todas as tarefas a partir do terminal com o comando yolo comanda.\n","\n","Ultralytics yolo utiliza a seguinte sintaxe:\n","```python\n","  yolo TASK MODE ARGS\n","\n","  Where   TASK (optional) is one of [detect, segment, classify]\n","          MODE (required) is one of [train, val, predict, export, track]\n","          ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","```"]},{"cell_type":"markdown","metadata":{"id":"YgjFAhye24X2"},"source":["### Validando o modelo de treinamento\n","Fornece um conjunto robusto de ferramentas e m√©tricas para avaliar o desempenho dos teus modelos de dete√ß√£o de objectos\n","- Precis√£o e Ajuste de hiperpar√¢metros\n","\n","**NOTA**: Os arquivos de treinamento foram gerados e armazenados no diretorio `runs`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvyYqLPUy5uC"},"outputs":[],"source":["%cd {HOME}\n","\n","target_model = YOLOv8(\"yolov8n.pt\")\n","target_model.train(DATA_YAML_PATH, epochs=5) # define quantas epochs"]},{"cell_type":"markdown","metadata":{"id":"cTm6gMo5qIrf"},"source":["### Exibir resultados de treinamento e validacao\n","**NOTA**: Os arquivos dos resultados de treinamento e validacao foram gerados e armazenados no diretorio `runs\\detect\\trainx`, onde x √© numero de 1 a n."]},{"cell_type":"markdown","metadata":{"id":"FMBBw4wx29Q5"},"source":["**Matriz de confusao**"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Image(filename=f'{HOME}/runs/detect/trainx/confusion_matrix.png', width=600)"]},{"cell_type":"markdown","metadata":{"id":"bZ8UP7Qw3BXZ"},"source":["**Metricas de treinamento**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z6U9XV5qXvv3"},"outputs":[],"source":["Image(filename=f'{HOME}/runs/detect/trainx/results.png', width=600)"]},{"cell_type":"markdown","metadata":{"id":"7OnzfoXT3EEV"},"source":["**Imagens validadas**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e5bANsRwlKmD"},"outputs":[],"source":["Image(filename=f'{HOME}/runs/detect/trainx/val_batch0_labels.jpg', width=600)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
